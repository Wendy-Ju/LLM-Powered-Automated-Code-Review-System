{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e220a7-8acd-4ea9-b5cc-6f3460b11b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Lengths:\n",
      "{'calculate_statistics': 12, 'find_outliers': 14, 'main': 10}\n",
      "\n",
      "Cyclomatic Complexity:\n",
      "{'calculate_statistics': 2, 'find_outliers': 4, 'main': 1}\n",
      "\n",
      "Duplicate Code Blocks (min 3 lines):\n",
      "Appears 2 times:\n",
      "\n",
      "    mean = stats[\"mean\"]\n",
      "    std_dev = stats[\"std_dev\"]\n",
      "------------------------------\n",
      "Appears 2 times:\n",
      "\n",
      "    print(\"Original Data Summary:\")\n",
      "    print(calculate_statistics(data))\n",
      "------------------------------\n",
      "Appears 2 times:\n",
      "\n",
      "    outliers = find_outliers(data)\n",
      "    print(f\"Detected Outliers: {outliers}\")\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Phase 1: Code Parsing and Feature Extraction\n",
    "\n",
    "import ast\n",
    "import hashlib\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "class CodeAnalyzer:\n",
    "    def __init__(self, code: str):\n",
    "        self.code = code\n",
    "        self.tree = ast.parse(code)\n",
    "        self.lines = code.splitlines()\n",
    "\n",
    "    def get_function_lengths(self):\n",
    "        \"\"\"Return the line length of each function.\"\"\"\n",
    "        func_lengths = {}\n",
    "        for node in ast.walk(self.tree):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                start = node.lineno\n",
    "                end = max(getattr(n, 'lineno', start) for n in ast.walk(node))\n",
    "                func_lengths[node.name] = end - start + 1\n",
    "        return func_lengths\n",
    "\n",
    "    def get_cyclomatic_complexity(self):\n",
    "        \"\"\"Return a rough cyclomatic complexity score per function.\"\"\"\n",
    "        complexity = defaultdict(int)\n",
    "        for node in ast.walk(self.tree):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                complexity[node.name] += 1  # function entry point\n",
    "                for sub in ast.walk(node):\n",
    "                    if isinstance(sub, (ast.If, ast.For, ast.While, ast.Try, ast.With, ast.And, ast.Or)):\n",
    "                        complexity[node.name] += 1\n",
    "        return dict(complexity)\n",
    "\n",
    "    def detect_code_duplication(self, min_lines=3):\n",
    "        \"\"\"Detect simple duplication by hashing code blocks.\"\"\"\n",
    "        hash_counts = Counter()\n",
    "        block_hash_map = {}\n",
    "\n",
    "        for i in range(len(self.lines) - min_lines + 1):\n",
    "            block = \"\\n\".join(self.lines[i:i + min_lines])\n",
    "            block_hash = hashlib.md5(block.strip().encode()).hexdigest()\n",
    "            hash_counts[block_hash] += 1\n",
    "            if block_hash not in block_hash_map:\n",
    "                block_hash_map[block_hash] = block\n",
    "\n",
    "        duplicated = {block_hash_map[h]: c for h, c in hash_counts.items() if c > 1}\n",
    "        return duplicated\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    with open(\"example.py\", \"r\") as f:\n",
    "        code = f.read()\n",
    "    \n",
    "    analyzer = CodeAnalyzer(code)\n",
    "    \n",
    "    print(\"Function Lengths:\")\n",
    "    print(analyzer.get_function_lengths())\n",
    "    \n",
    "    print(\"\\nCyclomatic Complexity:\")\n",
    "    print(analyzer.get_cyclomatic_complexity())\n",
    "    \n",
    "    print(\"\\nDuplicate Code Blocks (min 3 lines):\")\n",
    "    duplicates = analyzer.detect_code_duplication()\n",
    "    for block, count in duplicates.items():\n",
    "        print(f\"Appears {count} times:\\n{block}\\n{'-' * 30}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279bbc17-60b3-40e1-b462-a52caed5429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: LLM-Powered Code Review System (OpenAI SDK >= 1.0)\n",
    "\n",
    "import openai\n",
    "import tiktoken\n",
    "import time\n",
    "import logging\n",
    "\n",
    "openai.api_key = \"This is secret.\" # Insert your secret key here.\n",
    "\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "def count_tokens(text, model=\"gpt-3.5-turbo\"):\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "class LLMReviewer:\n",
    "    def __init__(self, model=\"gpt-3.5-turbo\"):\n",
    "        self.model = model\n",
    "        self.history = []\n",
    "\n",
    "    def review_code(self, code: str):\n",
    "        prompt = (\n",
    "            \"You are a professional software engineer. \"\n",
    "            \"Please review the following Python code and provide detailed, constructive feedback, \"\n",
    "            \"covering correctness, readability, style, modularity, documentation, and security risks.\\n\\n\"\n",
    "            f\"{code.strip()}\"\n",
    "        )\n",
    "\n",
    "        tokens_prompt = count_tokens(prompt)\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a senior software engineer performing a code review.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.4,\n",
    "                max_tokens=512\n",
    "            )\n",
    "\n",
    "            text = response.choices[0].message.content.strip()\n",
    "            usage = response.usage\n",
    "\n",
    "            self.history.append({\n",
    "                \"input_tokens\": tokens_prompt,\n",
    "                \"output_tokens\": usage.completion_tokens,\n",
    "                \"total_tokens\": usage.total_tokens,\n",
    "                \"feedback\": text,\n",
    "                \"timestamp\": time.time()\n",
    "            })\n",
    "\n",
    "            return {\n",
    "                \"feedback\": text,\n",
    "                \"input_tokens\": tokens_prompt,\n",
    "                \"output_tokens\": usage.completion_tokens,\n",
    "                \"total_tokens\": usage.total_tokens\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd77206-6297-421b-b567-1d0c6dfa810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPT-3.5 Feedback ===\n",
      "### Feedback:\n",
      "\n",
      "#### Correctness:\n",
      "1. The `calculate_statistics` function correctly calculates the mean, variance, and standard deviation of the input data. \n",
      "2. The `find_outliers` function correctly identifies outliers based on the threshold provided.\n",
      "\n",
      "#### Readability:\n",
      "1. Overall, the code is readable and easy to follow.\n",
      "2. Variable names are descriptive and convey their purpose.\n",
      "3. The code is well-formatted and consistent in style.\n",
      "\n",
      "#### Style:\n",
      "1. The code follows PEP 8 style guidelines, which is good.\n",
      "2. Functions are appropriately separated, and the main logic is encapsulated within them.\n",
      "3. The use of list comprehensions and built-in functions like `sum` makes the code concise and readable.\n",
      "\n",
      "#### Modularity:\n",
      "1. The code is modular, with separate functions for calculating statistics and finding outliers. This promotes code reusability.\n",
      "2. The main logic is isolated within functions, making it easier to maintain and test.\n",
      "\n",
      "#### Documentation:\n",
      "1. The code lacks docstrings for functions. Adding docstrings would improve the readability and maintainability of the code.\n",
      "2. Consider adding comments to explain complex logic or algorithms, especially in the `find_outliers` function.\n",
      "\n",
      "#### Security Risks:\n",
      "1. There are no apparent security risks in the provided code.\n",
      "2. However, when working with sensitive data, it's essential to ensure input validation and data sanitization to prevent security vulnerabilities.\n",
      "\n",
      "### Suggestions:\n",
      "1. Add docstrings to describe the purpose of each function, their parameters, and return values.\n",
      "2. Consider adding comments to explain the outlier detection logic in the `find_outliers` function for better understanding.\n",
      "3. You could enhance the `find_outliers` function to return both the outlier values and their indices for better analysis.\n",
      "4. It might be beneficial to handle cases where the input data is empty more explicitly, such as raising an exception or returning a meaningful message.\n",
      "5. Consider adding type hints to function parameters and return values for better code clarity and maintainability.\n",
      "\n",
      "Overall, the code is well-written and functional. By incorporating the suggested improvements, you can enhance its readability, maintainability, and robustness.\n",
      "Tokens used: 740\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "with open(\"example.py\", \"r\") as f:\n",
    "    code = f.read()\n",
    "\n",
    "reviewer = LLMReviewer()\n",
    "result = reviewer.review_code(code)\n",
    "\n",
    "print(\"=== GPT-3.5 Feedback ===\")\n",
    "print(result[\"feedback\"])\n",
    "print(f\"Tokens used: {result['total_tokens']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a9419b6-b5c0-47ab-8c74-f6e9f0bfdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3: Issue Categorization\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Predefined patterns for categorizing LLM feedback\n",
    "CATEGORY_PATTERNS = {\n",
    "    \"Style\": [\n",
    "        r\"\\bPEP8\\b\", r\"indentation\", r\"naming\", r\"formatting\", r\"line length\", r\"readability\"\n",
    "    ],\n",
    "    \"Bug\": [\n",
    "        r\"\\bbug\\b\", r\"\\berror\\b\", r\"off[- ]by[- ]one\", r\"\\bcrash\\b\", r\"\\bunexpected\\b\",\n",
    "        r\"\\bincorrect\\b\", r\"unused variable\", r\"edge case\"\n",
    "    ],\n",
    "    \"Security\": [\n",
    "        r\"SQL injection\", r\"\\bXSS\\b\", r\"hardcoded (secret|password|token)\",\n",
    "        r\"vulnerability\", r\"input validation\", r\"data sanitization\"\n",
    "    ],\n",
    "    \"Documentation\": [\n",
    "        r\"docstring\", r\"\\bcomment\\b\", r\"documentation\", r\"missing explanation\", r\"clarity\",\n",
    "        r\"explain the function\", r\"not well documented\", r\"function description\"\n",
    "    ],\n",
    "    \"Modularity\": [\n",
    "        r\"\\breusable\\b\", r\"split.*function\", r\"too long\", r\"separation of concerns\",\n",
    "        r\"single responsibility\", r\"refactor into smaller functions\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def categorize_feedback(feedback: str) -> dict:\n",
    "    \"\"\"\n",
    "    Categorizes LLM-generated feedback into predefined issue types.\n",
    "    Parameters:\n",
    "        feedback (str): The LLM-generated feedback string\n",
    "    Returns:\n",
    "        dict: A mapping from category name to a list of matched feedback lines\n",
    "    \"\"\"\n",
    "    categorized = defaultdict(list)\n",
    "    lines = feedback.strip().splitlines()\n",
    "\n",
    "    for line in lines:\n",
    "        cleaned_line = line.strip()\n",
    "        if not cleaned_line:\n",
    "            continue\n",
    "        for category, patterns in CATEGORY_PATTERNS.items():\n",
    "            if any(re.search(pattern, cleaned_line, re.IGNORECASE) for pattern in patterns):\n",
    "                categorized[category].append(cleaned_line)\n",
    "                break  # Assign to only the first matched category\n",
    "    return dict(categorized)\n",
    "\n",
    "def print_categorized_feedback(categorized: dict):\n",
    "    \"\"\"\n",
    "    Nicely prints categorized feedback as numbered lists.\n",
    "    Parameters:\n",
    "        categorized (dict): Output from categorize_feedback()\n",
    "    \"\"\"\n",
    "    if not categorized:\n",
    "        print(\"No categorizable issues found.\")\n",
    "        return\n",
    "\n",
    "    for category, items in categorized.items():\n",
    "        print(f\"{category} Issues ({len(items)}):\")\n",
    "        print(\"-\" * (len(category) + 9))\n",
    "        for idx, issue in enumerate(items, 1):\n",
    "            print(f\"{idx}. {issue}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d19a7e80-b576-4fc9-8671-b9761a1e07bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style Issues (3):\n",
      "--------------\n",
      "1. #### Readability:\n",
      "2. 1. The code lacks docstrings for functions. Adding docstrings would improve the readability and maintainability of the code.\n",
      "3. Overall, the code is well-written and functional. By incorporating the suggested improvements, you can enhance its readability, maintainability, and robustness.\n",
      "\n",
      "Documentation Issues (3):\n",
      "----------------------\n",
      "1. #### Documentation:\n",
      "2. 1. Add docstrings to describe the purpose of each function, their parameters, and return values.\n",
      "3. 5. Consider adding type hints to function parameters and return values for better code clarity and maintainability.\n",
      "\n",
      "Security Issues (1):\n",
      "-----------------\n",
      "1. 2. However, when working with sensitive data, it's essential to ensure input validation and data sanitization to prevent security vulnerabilities.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feedback_text = result[\"feedback\"]\n",
    "categorized = categorize_feedback(feedback_text)\n",
    "print_categorized_feedback(categorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa95baa7-e905-4b71-addc-c88e0dca607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 4: Static Rule-Based Validation\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class RuleBasedValidator:\n",
    "    def __init__(self, code: str):\n",
    "        self.code = code\n",
    "        self.lines = code.splitlines()\n",
    "        self.results = defaultdict(list)\n",
    "\n",
    "    def run_all_checks(self):\n",
    "        \"\"\"\n",
    "        Run all static rule-based code checks.\n",
    "        Returns:\n",
    "            dict: category -> list of issue messages\n",
    "        \"\"\"\n",
    "        self.check_hardcoded_secrets()\n",
    "        self.check_unsafe_functions()\n",
    "        self.check_missing_type_hints()\n",
    "        self.check_unused_imports()\n",
    "        return dict(self.results)\n",
    "\n",
    "    def check_hardcoded_secrets(self):\n",
    "        pattern = r\"(password|secret|token)\\s*=\\s*['\\\"].+['\\\"]\"\n",
    "        for i, line in enumerate(self.lines):\n",
    "            if re.search(pattern, line, re.IGNORECASE):\n",
    "                self.results[\"Security\"].append(\n",
    "                    f\"Line {i + 1}: Hardcoded secret or password → `{line.strip()}`\"\n",
    "                )\n",
    "\n",
    "    def check_unsafe_functions(self):\n",
    "        for i, line in enumerate(self.lines):\n",
    "            if \"eval(\" in line or \"exec(\" in line:\n",
    "                self.results[\"Security\"].append(\n",
    "                    f\"Line {i + 1}: Unsafe use of `eval()` or `exec()` → `{line.strip()}`\"\n",
    "                )\n",
    "\n",
    "    def check_missing_type_hints(self):\n",
    "        func_def_pattern = r\"def\\s+\\w+\\((.*?)\\):\"\n",
    "        for i, line in enumerate(self.lines):\n",
    "            if re.match(func_def_pattern, line) and \"->\" not in line:\n",
    "                self.results[\"Style\"].append(\n",
    "                    f\"Line {i + 1}: Function may be missing return type hint → `{line.strip()}`\"\n",
    "                )\n",
    "\n",
    "    def check_unused_imports(self):\n",
    "        imports = {}\n",
    "        usage = set()\n",
    "        for i, line in enumerate(self.lines):\n",
    "            if line.startswith(\"import \") or line.startswith(\"from \"):\n",
    "                name = line.split()[1]\n",
    "                imports[name] = i + 1\n",
    "            for word in re.findall(r\"\\b\\w+\\b\", line):\n",
    "                usage.add(word)\n",
    "\n",
    "        for name, lineno in imports.items():\n",
    "            if name not in usage:\n",
    "                self.results[\"Style\"].append(\n",
    "                    f\"Line {lineno}: Unused import detected → `{self.lines[lineno - 1].strip()}`\"\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c86fb71-3608-4fec-aa8f-1b884476c2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style Issues (3):\n",
      "--------------\n",
      "- Line 1: Function may be missing return type hint → `def calculate_statistics(data):`\n",
      "- Line 15: Function may be missing return type hint → `def find_outliers(data, threshold=2):`\n",
      "- Line 30: Function may be missing return type hint → `def main():`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validator = RuleBasedValidator(code)\n",
    "static_issues = validator.run_all_checks()\n",
    "\n",
    "for category, issues in static_issues.items():\n",
    "    print(f\"{category} Issues ({len(issues)}):\")\n",
    "    print(\"-\" * (len(category) + 9))\n",
    "    for issue in issues:\n",
    "        print(f\"- {issue}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6299b535-d6b8-47b4-b743-8465aad91322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 5: Unified Review Result (LLM + Rule-based)\n",
    "\n",
    "def merge_reviews(llm_categorized: dict, static_validated: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Combine LLM-categorized feedback with rule-based results.\n",
    "    Prioritizes non-duplicate entries and aligns by category.\n",
    "    \"\"\"\n",
    "    merged = defaultdict(list)\n",
    "\n",
    "    all_categories = set(llm_categorized) | set(static_validated)\n",
    "    for category in all_categories:\n",
    "        lines = set()\n",
    "        if category in llm_categorized:\n",
    "            lines.update(llm_categorized[category])\n",
    "        if category in static_validated:\n",
    "            lines.update(static_validated[category])\n",
    "        merged[category] = sorted(lines)\n",
    "\n",
    "    return dict(merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4d13403-cbac-4750-9b3f-e608425b5b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style Issues (6):\n",
      "--------------\n",
      "1. #### Readability:\n",
      "2. 1. The code lacks docstrings for functions. Adding docstrings would improve the readability and maintainability of the code.\n",
      "3. Line 15: Function may be missing return type hint → `def find_outliers(data, threshold=2):`\n",
      "4. Line 1: Function may be missing return type hint → `def calculate_statistics(data):`\n",
      "5. Line 30: Function may be missing return type hint → `def main():`\n",
      "6. Overall, the code is well-written and functional. By incorporating the suggested improvements, you can enhance its readability, maintainability, and robustness.\n",
      "\n",
      "Documentation Issues (3):\n",
      "----------------------\n",
      "1. #### Documentation:\n",
      "2. 1. Add docstrings to describe the purpose of each function, their parameters, and return values.\n",
      "3. 5. Consider adding type hints to function parameters and return values for better code clarity and maintainability.\n",
      "\n",
      "Security Issues (1):\n",
      "-----------------\n",
      "1. 2. However, when working with sensitive data, it's essential to ensure input validation and data sanitization to prevent security vulnerabilities.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine results from Phase 3 + Phase 4\n",
    "combined_results = merge_reviews(\n",
    "    categorize_feedback(result[\"feedback\"]),  # from GPT\n",
    "    RuleBasedValidator(code).run_all_checks() # from static rules\n",
    ")\n",
    "\n",
    "# Print full merged result\n",
    "print_categorized_feedback(combined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846a63d-5e6d-4e13-8f12-b24f27d1b49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
